{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finite differences in 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We approximate the boundary value problem consisting of the following PDE:\n",
    "$$\n",
    "-u''(x) + u(x) = f(x), \\qquad  0 < x < 1.\n",
    "$$\n",
    "(This is actually an ODE since the unknown is a function of a single real variable $x$.) This equation is supplemented with  Dirichlet boundary conditions \n",
    "$$\n",
    "u(0) = u(1) = 0\n",
    "$$\n",
    "at both ends. \n",
    "\n",
    "The purpose of this notebooks is to quickly illustrate the standard finite difference method for solving this, taking the opportunity to also ensure that we are all on the same page regarding the python  prerequisites. Let's begin by importing the `numpy` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximating the derivative \n",
    "\n",
    "It is very easy to understand and implement finite differences. The finite difference approximation of $u(x)$ is a finite sequence $u_i$. Each $u_i$ approximates $u(x_i)$ at a point $x_i$ in the interval $[0, 1]$ where we need the solution. The sequence of points $x_i$ may be thought of a grid or mesh of the domain $[0, 1]$.\n",
    "\n",
    "To approximate the ODE, we need to approximate derivatives using the grid. The **forward difference** approximation of $d u / dx$ is \n",
    "$$\n",
    "[D_+u]_i = \\frac{ u(x_{i+1}) - u(x_i) }{ x_{i+1} - x_i}, \\qquad\n",
    "u'(x_i) \\approx [D_+u]_i.\n",
    "$$\n",
    "The **backward difference** approximation is \n",
    "$$\n",
    "[D_-u]_i = \\frac{ u(x_{i}) - u(x_{i-1}) }{ x_i - x_{i-1}}, \\qquad\n",
    "u'(x_i) \\approx [D_+u]_i.\n",
    "$$\n",
    "Note that by Taylor's theorem, when $u$ is smooth, both approximate the derivative as $x_{i\\pm 1} \\to x_i$:\n",
    "$$\n",
    "\\frac{d u }{d x}(x_i) \\approx [D_+ u]_i, \\qquad \\frac{d u }{d x}(x_i) \\approx [D_- u]_i. \n",
    "$$\n",
    "In fact, from calculus tools, you immediately see that both the approximations are $O(h)$ where $h$ is the spacing between the points on a uniform grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The finite difference system\n",
    "\n",
    "For approximating the ODE $-u'' +u = f$, we need to approximate the second derivative, not the first. Obviously there are many ways to combine the above two differences to get an approximation to $u''$, \n",
    "$$\n",
    "\\frac{d }{dx} \\frac{d u}{d x} (x_i) \\approx [D_\\pm D_\\pm u]_i.\n",
    "$$\n",
    "Depending on the choice in $\\pm$, we have four possible approximations. \n",
    "\n",
    "However, some are $O(h^2)$ accurate, while others are only $O(h)$-accurate. (**Exercise:** Which? Why?)\n",
    "\n",
    "The **Central Difference Formula** for approximating the second derivative is \n",
    "$$\n",
    "\\frac{d }{dx} \\frac{d u}{d x} (x_i) \\approx [D_+D_- u]_i \\equiv [D_-D_+ u]_i,\n",
    "$$\n",
    "which can be alternately written on a uniform grid of mesh size $h$ as\n",
    "$$\n",
    "\\begin{aligned}\n",
    "u''(x_i) \n",
    "& \\approx {u_{i+1}  - 2 u_i + u_{i-1} \\over h^2}.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the finite difference system\n",
    "\n",
    "\n",
    "The **matrix** of the *central second finite difference* operator on a grid of *just* 5 equally spaced points, two of which have zero boundary conditions, can be \"made by hand\" as a `numpy` array, as follows (save for a  factor of $-1/h^2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[ 2, -1,  0], \n",
    "              [-1,  2, -1], \n",
    "              [ 0, -1,  2]])\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large number of grid points, we need an automatic way to make this matrix. Numpy provides many ways to create matrices quickly. For example, the `diag` command generates matrices with input entries in the diagonal, superdiagonals, or subdiagonals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "2 * np.diag(np.ones(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 2 * np.diag(np.ones(N)) +    \\\n",
    "    np.diag(-np.ones(N-1), -1) + \\\n",
    "    np.diag(-np.ones(N-1), 1) \n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `A` when multiplied by a vector of values of $u/h^2$ gives approximate values of $-u''$. Using this we can approximate the left hand side of the PDE $-u'' + u = f$, as done next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the difference equation system\n",
    "\n",
    "\n",
    "Adding values of $u$ to the discretization of $-u''$ we obtain the left hand side of the finite difference system. The right hand side just consists of a vector values of $f$ at the grid points.\n",
    "\n",
    "We solve the finite difference equations using the built-in inverse routine in numpy's `linalg` submodule. (Note the definition of a python function and how we use `@` for numpy's matrix multiplication.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(f, h):\n",
    "    size = len(f)\n",
    "    A = (1/h**2) * (2 * np.diag(np.ones(size))    + \\\n",
    "                    np.diag(-np.ones(size-1), -1) + \n",
    "                    np.diag(-np.ones(size-1), 1)) + np.eye(size)\n",
    "    return np.linalg.inv(A) @ f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have an approximate solution to the boundary value problem in the returned vector. Is it any good? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verification** is a key step while designing and implementing  numerical methods.\n",
    "\n",
    "We will verify that the `solve` function is solving as expected by the **method of manufactured solutions**, which is just a fancy name for  the following simple idea: pick your favorite smooth function $u$ satisfying the boundary conditions, then generate the right hand side $f$ that would give your $u$ as the exact solution by applying the differential operator to $u$. \n",
    "\n",
    "In the check below, I will use\n",
    "$$\n",
    "u = \\sin(x)\n",
    "$$\n",
    "on an interval $(0, 3\\pi)$ so that the zero boundary conditions hold. Then put $f = -u'' + u = 2\\sin(x)$. Let's provide this $f$ to `solve` and see whether it outputs an approximation to $u = \\sin(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An equally spaced grid in any interval is easily made using the `linspace` facility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 3*np.pi, num=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's \"manufacture\"  the data $f$ for the manufactured solution $u=\\sin(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30    # the system becomes more expensive to solve for large N\n",
    "h = 3*np.pi / N\n",
    "x = np.linspace(0, 3*np.pi, num=N)\n",
    "f = 2 * np.sin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One point to note about the boundary points: when we solve, we make sure not to give the end point values in `f` (as the solution there is already determined by the boundary conditions).  Restricting $f$ outside of these points is done by **slicing** in numpy (which you should definitely learn if you don't know already) as in `f[1:-1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = solve(f[1:-1], h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualizing the solution, we use `matplotlib` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(u, '.-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can you make sure the end points with the known zero solution values  are also included in the final plot? This is again done using slicing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu = np.zeros(N)\n",
    "uu[1:-1] = u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's conclude by comparing the exact solution with the numerical solution by plotting both in the same scene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(uu, '.', label='computed solution')\n",
    "plt.plot(np.sin(x), ':', label='exact solution', alpha=0.5)\n",
    "plt.grid(True)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the `solve` function captured something close to the exact solution.\n",
    "\n",
    "Going back through this notebook, you can easily change the mesh parameter to make $h$ smaller. Then repeating the above steps, you will see that the discrete solution points gets closer to exact solution curve. \n",
    "\n",
    "We will proceed to study finite elements. Then, unlike the above,  we will think of the discrete solution as a function (and not as a set of discrete values as above). The function will be from a finite-dimensional space (called a finite element space)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
