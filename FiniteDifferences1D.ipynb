{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finite differences in 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We approximate the boundary value problem consisting of the following partial differential equation (PDE), actually an ODE in this case:\n",
    "$$\n",
    "-u''(x) + u(x) = f(x), \\qquad  0 < x < 1.\n",
    "$$\n",
    "This equation is supplemented with  Dirichlet boundary conditions \n",
    "$$\n",
    "u(0) = u(1) = 0\n",
    "$$\n",
    "at both ends. \n",
    "\n",
    "We quickly illustrate the standard finite difference method for solving this, taking the opportunity to also ensure that we are all on the same page regarding python and numpy prerequisites. Let's begin by importing `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the finite difference system\n",
    "\n",
    "\n",
    "Finite differences approximate the derivative of a real-valued \n",
    "function  $f$ (of  a single real variable $x$)\n",
    "by \n",
    "\n",
    "$$\n",
    "f'(x) \\approx {f(x+h/2) - f(x-h/2) \\over h}\n",
    "$$\n",
    "\n",
    "We take one further step and approximate the second derivative by \n",
    "$$\n",
    "\\begin{aligned}\n",
    "f''(x) \n",
    "& \n",
    "\\approx { f'(x+h/2) - f'(x-h/2) \\over h }\n",
    "\\\\\n",
    "& \\approx { \\left(\\frac{f(x+h/2+h/2) - f(x+h/2-h/2)}{h}\\right) - \\left(\\frac{f(x-h/2) - f(x-h/2-h/2)}{h} \\right)\\over h }\n",
    "\\\\\n",
    "& \\approx {f(x+h) - 2f(x) + f(x-h)\\over h^2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "This is the **Central Difference Formula** for the second derivative.\n",
    "\n",
    "The **matrix** of the *central second finite difference* operator on a grid of *just* 5 equally spaced points, two of which have zero boundary conditions, can be \"made by hand\" as a `numpy` array, as follows, postponing the multiplication by the factor $1/h^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[ 2, -1,  0], \n",
    "              [-1,  2, -1], \n",
    "              [ 0, -1,  2]])\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large number of grid points, we need an automatic way to make this matrix. Numpy provides many ways to create matrices quickly. For example, the `diag` command generates matrices with input entries in the diagonal, superdiagonals, or subdiagonals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "2 * np.diag(np.ones(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 2 * np.diag(np.ones(N)) +    \\\n",
    "    np.diag(-np.ones(N-1), -1) + \\\n",
    "    np.diag(-np.ones(N-1), 1)  + \\\n",
    "    np.eye(N)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the difference equation system\n",
    "\n",
    "We solve the finite difference equations using the built-in inverse routine in numpy's `linalg` submodule. Note how we create functions using `def` in python and how we use `@` for numpy matrix multiply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(f, h):\n",
    "    size = len(f)\n",
    "    A = (1/h**2) * (2 * np.diag(np.ones(size))    + \\\n",
    "                    np.diag(-np.ones(size-1), -1) + \n",
    "                    np.diag(-np.ones(size-1), 1)) + np.eye(size)\n",
    "    return np.linalg.inv(A) @ f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have an approximate solution to the boundary value problem in the returned vector. Is this any good? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verification** is a key step while studying numerical methods.\n",
    "\n",
    "We will verify that the `solve` function is solving as expected by the **method of manufactured solutions**, which is just a fancy name for  the following simple idea: pick your favorite smooth function $u$ satisfying the boundary conditions, then generate the right hand side $f$ that would give your $u$ as the exact solution by applying the differential operator to $u$. \n",
    "\n",
    "In the check below, I will use\n",
    "$$\n",
    "u = \\sin(x)\n",
    "$$\n",
    "on an interval $(0, 3\\pi)$ so that the zero boundary conditions hold. Then put $f = -u'' + u = 2\\sin(x)$. Let's provide this $f$ to `solve` and see whether it outputs an approximation to $u = \\sin(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An equally spaced grid in an interval is easily made using the `linspace` facility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 3*np.pi, num=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's \"manufacture\"  the data $f$ for the manufactured solution $u=\\sin(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30    # the system becomes more expensive to solve for large N\n",
    "h = 3*np.pi / N\n",
    "x = np.linspace(0, 3*np.pi, num=N)\n",
    "f = 2 * np.sin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One point to note about the boundary points: when we solve, we make sure not to give the end point values in `f` (as the solution there is already determined by the boundary conditions).  Restricting $f$ outside of these points is done by **slicing** in numpy (which you should definitely learn if you don't know already) as in `f[1:-1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = solve(f[1:-1], h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualizing the solution, we use `matplotlib` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(u, '.-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can you make sure the end points with the known zero solution values  are also included in the final plot? This is again done using slicing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu = np.zeros(N)\n",
    "uu[1:-1] = u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's conclude by comparing the exact solution with the numerical solution by plotting both in the same scene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(uu, '.', label='computed solution')\n",
    "plt.plot(np.sin(x), ':', label='exact solution', alpha=0.5)\n",
    "plt.grid(True)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the `solve` function captured something close to the exact solution.\n",
    "\n",
    "Going back through this notebook, you can easily change the mesh parameter to make $h$ smaller. Then repeating the above steps, you will see that the discrete solution points gets closer to exact solution curve. When we study finite elements, we will think of the discrete solution also as a function, not as a set of discrete values as above. We will then measure the difference of exact and discrete solutions using function space norms like the $L^2$ norm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
